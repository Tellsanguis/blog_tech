---
sidebar_position: 2
---

# Premi√®re version : le Homelab "HA" monomachine (projet initial)

## Introduction

**Note importante** : Cette page d√©crit le **projet initial** que j'avais envisag√© pour exp√©rimenter avec Kubernetes. Ce projet a **√©volu√©** vers une d√©cision finale diff√©rente : un cluster Proxmox 3 n≈ìuds (voir [Cluster 3 noeuds Proxmox](./cluster-3-noeuds-proxmox.md)).

L'id√©e initiale √©tait de cr√©er une **√©tape transitoire** vers une infrastructure distribu√©e compl√®te, en exp√©rimentant avec Kubernetes (K3S), l'Infrastructure as Code (OpenTofu/Terraform), Git et les pipelines CI/CD, tout en restant sur une seule machine physique.

## Objectifs de cette version

### Apprentissage pratique

Cette infrastructure monomachine permet d'acqu√©rir une exp√©rience concr√®te sur :

1. **Kubernetes (K3S)** :
   - Installation et configuration d'un cluster K3S
   - Gestion des pods, d√©ploiements, services
   - Configuration des ingress controllers
   - Gestion du stockage persistant
   - Utilisation de Helm pour les d√©ploiements

2. **Infrastructure as Code** :
   - D√©claration de l'infrastructure avec OpenTofu/Terraform
   - Versionnement de toute la configuration dans Git
   - Modules r√©utilisables et bonnes pratiques IaC

3. **GitOps et CI/CD** :
   - Int√©gration avec Forgejo Actions pour les pipelines
   - D√©ploiement automatique sur push Git (GitOps)
   - Tests automatis√©s avant d√©ploiement
   - Rollback automatique en cas d'√©chec

4. **Observabilit√©** :
   - Stack Prometheus + Grafana pour les m√©triques
   - Loki pour la centralisation des logs
   - Alerting et dashboards personnalis√©s

### Validation des concepts

L'objectif √©tait de valider les concepts suivants avant d'investir dans du mat√©riel :
- Valider l'architecture globale
- Tester les configurations Kubernetes
- Affiner les processus de d√©ploiement
- Identifier les services compatibles avec K8S

**√âvolution du projet** : Apr√®s r√©flexion, j'ai d√©cid√© d'utiliser des **VMs multiples** pour simuler un vrai cluster et apprendre les aspects distribu√©s d√®s le d√©but. Cette approche m'a permis d'exp√©rimenter avec la r√©partition de charge, la tol√©rance aux pannes et les politiques d'affinit√©, ce qui n'aurait pas √©t√© possible sur un n≈ìud unique.

## Architecture r√©seau

Le sch√©ma illustre l'architecture r√©seau de cette premi√®re version :

![Sch√©ma r√©seau du homelab futur](/img/diagrams/homelab-futur-network.png)

[üì• T√©l√©charger le PDF](/img/diagrams/homelab-futur-network.pdf)

### Composants de l'architecture

**Infrastructure physique/virtuelle** :
- Serveur unique avec ressources suffisantes (16+ GB RAM, 4+ c≈ìurs CPU)
- Stockage local pour les volumes persistants
- R√©seau local standard (pas de VLAN segment√©)

**Cluster K3S** :
- Node unique (control plane + worker combin√©s)
- Ingress controller (Traefik int√©gr√© ou NGINX)
- Local Path Provisioner pour le stockage dynamique

**Services d√©ploy√©s** :
- Services applicatifs migr√©s depuis Docker Compose
- Stack d'observabilit√© (Prometheus, Grafana, Loki)
- ArgoCD pour le GitOps
- Services de test et d√©veloppement

**CI/CD** :
- Forgejo avec Actions pour les pipelines
- D√©ploiements automatiques via ArgoCD
- Tests de validation automatis√©s

## Ce qu'on peut apprendre

Cette infrastructure monomachine permet d'acqu√©rir des comp√©tences essentielles :

### Comp√©tences Kubernetes

- **D√©ploiements** : Cr√©ation et gestion de Deployments, StatefulSets, DaemonSets
- **Services** : LoadBalancer, ClusterIP, NodePort, ExternalName
- **Ingress** : Configuration du routing HTTP/HTTPS
- **ConfigMaps et Secrets** : Gestion des configurations et credentials
- **Volumes** : PersistentVolumes, PersistentVolumeClaims, StorageClasses
- **RBAC** : Gestion des permissions et r√¥les
- **Namespaces** : Isolation logique des applications
- **Labels et Selectors** : Organisation et s√©lection des ressources
- **Health checks** : Liveness, Readiness et Startup probes

### Comp√©tences DevOps

- **Infrastructure as Code** : D√©claration compl√®te de l'infrastructure
- **GitOps** : Synchronisation automatique Git ‚Üí Cluster
- **CI/CD** : Pipelines de test, build et d√©ploiement
- **Monitoring** : M√©triques, alertes, dashboards
- **Logging** : Centralisation et analyse des logs
- **S√©curit√©** : Network Policies, Pod Security Standards
- **Helm** : Packaging et d√©ploiement d'applications complexes

### Comp√©tences en automatisation

- **Ansible** : Provisioning automatique du serveur et installation K3S
- **OpenTofu** : Gestion d√©clarative de l'infrastructure
- **Scripts** : Automatisation des t√¢ches r√©currentes
- **Backups** : Strat√©gies de sauvegarde des volumes et √©tats

## Limitations de cette approche

### 1. Pas de vraie haute disponibilit√© (HA)

**Limitation principale** : Avec une seule machine, il n'y a **pas de redondance** :

- Si le serveur tombe en panne, tous les services sont indisponibles
- Pas de basculement automatique (failover)
- Maintenance = downtime obligatoire
- Point unique de d√©faillance (Single Point of Failure - SPOF)

**Ce qui n√©cessiterait plusieurs n≈ìuds physiques ou VMs** :
- Simulation r√©aliste de pannes r√©seau entre n≈ìuds
- Performance r√©seau inter-n≈ìuds en conditions r√©elles
- Consommation √©lectrique et gestion thermique d'un vrai cluster

### 2. Stockage distribu√© impossible √† tester

**Limitation critique** : Le stockage distribu√© (Ceph, Linstor DRBD, Longhorn avec r√©plication) n√©cessite **au minimum 3 n≈ìuds** pour garantir la redondance :

- **Ceph** : Requiert 3 n≈ìuds minimum (id√©alement 5+) pour le quorum et la r√©plication
- **Linstor DRBD** : N√©cessite plusieurs n≈ìuds pour la r√©plication synchrone des donn√©es
- **Longhorn** (r√©plication) : Ne peut pas r√©pliquer les donn√©es sur d'autres n≈ìuds

**Cons√©quences** :
- Utilisation du Local Path Provisioner uniquement (stockage non r√©pliqu√©)
- Pas d'exp√©rience sur la gestion du stockage distribu√©
- Pas de simulation de panne de disque avec r√©cup√©ration automatique
- Performances limit√©es (pas de parall√©lisation des I/O)

**Ce qu'on ne peut pas apprendre** :
- Configuration et tuning de Ceph (OSDs, MONs, MGRs)
- Gestion des placement groups et crush maps
- R√©plication et r√©silience du stockage
- Performance du stockage distribu√© vs local
- Strat√©gies de backup dans un syst√®me distribu√©

### 3. Scalabilit√© limit√©e

**Pas de scaling horizontal r√©el** :
- Impossible d'ajouter des n≈ìuds workers pour augmenter la capacit√©
- Limitations mat√©rielles de la machine unique (CPU, RAM, r√©seau)
- Pas d'exp√©rience sur l'auto-scaling (Horizontal Pod Autoscaler sur plusieurs n≈ìuds)

**Ce qu'on ne peut pas apprendre** :
- Ajout et retrait dynamique de n≈ìuds
- Load balancing entre n≈ìuds
- Gestion de la capacit√© globale du cluster
- Politiques de placement des pods selon les ressources disponibles

### 4. R√©seau simplifi√©

**Pas de simulation de r√©seau distribu√©** :
- Tous les pods sont sur la m√™me machine physique
- Latence r√©seau n√©gligeable (pas de simulation r√©elle)
- Pas de complexit√© li√©e aux CNI multi-n≈ìuds
- Pas de VLAN ou segmentation r√©seau avanc√©e

**Ce qu'on ne peut pas apprendre** :
- Configuration de CNI avanc√©s (Cilium, Calico avec BGP)
- Network policies complexes entre n≈ìuds
- Performance r√©seau inter-n≈ìuds
- Gestion des overlays r√©seau (VXLAN, etc.)

### 5. Pas de simulation de pannes r√©alistes

**Limitations pour le chaos engineering** :
- Impossible de simuler une panne de n≈ìud (on n'a qu'un seul n≈ìud)
- Pas de test de basculement automatique
- Pas de v√©rification de la reprise apr√®s sinistre (DR)

**Ce qu'on ne peut pas apprendre** :
- Proc√©dures de gestion de crise
- Temps de r√©cup√©ration r√©els (RTO/RPO)
- Comportement du cluster en situation d√©grad√©e

## Pourquoi commencer par une version monomachine ?

Malgr√© les limitations, cette approche pr√©sente des **avantages significatifs** :

### 1. Co√ªt et simplicit√©

- **Investissement r√©duit** : Pas besoin d'acheter 3-5 serveurs imm√©diatement
- **Consommation √©lectrique** : Un seul serveur √† alimenter
- **Espace physique** : Pas besoin de rack ou d'infrastructure r√©seau complexe
- **Maintenance** : Moins de machines = moins de pannes potentielles

### 2. Courbe d'apprentissage progressive

- **Complexit√© ma√Ætris√©e** : Se concentrer sur Kubernetes sans la complexit√© multi-n≈ìuds
- **Debugging simplifi√©** : Moins de points de d√©faillance √† diagnostiquer
- **Erreurs moins co√ªteuses** : Reconfigurer une machine est plus rapide que 5

### 3. Validation de l'architecture

- **Test des services** : V√©rifier quels services fonctionnent bien sur K8S
- **Optimisation des configurations** : Affiner les ressources (CPU, RAM) par service
- **Identification des probl√®mes** : D√©tecter les incompatibilit√©s avant de scaler

### 4. Pr√©paration √† l'√©volution

Cette version sert de **fondation** pour le cluster complet :
- Code IaC r√©utilisable (OpenTofu/Ansible)
- Manifests Kubernetes test√©s et valid√©s
- Pipelines CI/CD op√©rationnels
- Documentation compl√®te des processus

## √âvolution vers un vrai cluster

Une fois cette version stabilis√©e, l'√©volution vers un cluster multi-n≈ìuds devient naturelle :

### Mat√©riel suppl√©mentaire n√©cessaire

**Minimum pour un cluster HA fonctionnel** :
- 3 n≈ìuds (1 control plane + 2 workers, ou 3 n≈ìuds mixtes)
- Switch r√©seau Gigabit (ou 10GbE pour meilleures performances)
- Stockage distribu√© (Ceph requiert id√©alement 5 n≈ìuds)

**Id√©al pour tester toutes les fonctionnalit√©s** :
- 5 n≈ìuds (3 control plane + 3 workers avec stockage Ceph)
- Switch manageable pour VLAN
- Onduleur (UPS) pour √©viter les corruptions de donn√©es

### Migration progressive

**Strat√©gie de migration** :
1. Ajouter un deuxi√®me n≈ìud au cluster existant
2. Tester la r√©partition des pods entre n≈ìuds
3. Ajouter un troisi√®me n≈ìud pour activer HA
4. D√©ployer Ceph ou Linstor pour le stockage distribu√©
5. Migrer les workloads critiques avec r√©plication
6. Configurer les Network Policies avanc√©es

### R√©utilisation du code existant

**Ce qui reste valide** :
- Manifests Kubernetes (Deployments, Services, Ingress)
- Configurations Helm
- Pipelines CI/CD
- Scripts d'automatisation Ansible

**Ce qui doit √™tre adapt√©** :
- StorageClass : migration vers Ceph/Linstor
- PodDisruptionBudgets : garantir la disponibilit√©
- Affinit√©/Anti-affinit√© : r√©partir les pods intelligemment
- Configuration r√©seau : CNI multi-n≈ìuds

## Conclusion et √©volution vers le cluster 3 n≈ìuds

Ce projet initial de homelab "HA" monomachine a √©t√© une **r√©flexion importante** dans l'√©volution de mon infrastructure :

**Points positifs de la r√©flexion initiale** :
- Identification claire des objectifs d'apprentissage Kubernetes
- Validation de l'architecture et des configurations cibles
- Compr√©hension des limitations d'une approche monomachine

**D√©cision finale** :
Apr√®s avoir analys√© les limitations, notamment l'impossibilit√© de tester les aspects distribu√©s (haute disponibilit√©, stockage Ceph, r√©partition de charge), j'ai d√©cid√© d'opter directement pour un **cluster Proxmox 3 n≈ìuds**.

Cette d√©cision permet :
- D'exp√©rimenter avec de vraies VMs multiples simulant un cluster distribu√©
- De tester la haute disponibilit√© et le stockage distribu√© (Ceph)
- D'apprendre les aspects r√©seau complexes d'un cluster r√©el
- De construire une base solide pour une infrastructure production-ready

Pour plus de d√©tails sur l'architecture finale retenue, voir la page [Cluster 3 noeuds Proxmox](./cluster-3-noeuds-proxmox.md).
